[
    {
        "title": "Hybrid Transformer with Multi-level Fusion for\nMultimodal Knowledge Graph Completion\n",
        "abstract": "Multimodal Knowledge Graphs (MKGs), which organize visual-\ntext factual knowledge, have recently been successfully applied\nto tasks such as information retrieval, question answering, and\nrecommendation system. Since most MKGs are far from complete,\nextensive knowledge graph completion studies have been proposed\nfocusing on the multimodal entity, relation extraction and link pre-\ndiction. However, different tasks and modalities require changes\nto the model architecture, and not all images/objects are relevant\nto text input, which hinders the applicability to diverse real-world\nscenarios. In this paper, we propose a hybrid transformer with\nmulti-level fusion to address those issues. Specifically, we lever-\nage a hybrid transformer architecture with unified input-output\nfor diverse multimodal knowledge graph completion tasks. More-\nover, we propose multi-level fusion, which integrates visual and\ntext representation via coarse-grained prefix-guided interaction\nand fine-grained correlation-aware fusion modules. We conduct\nextensive experiments to validate that our MKGformer can obtain\nSOTA performance on four datasets of multimodal link prediction,\nmultimodal RE, and multimodal NER1.\n "
    },
    {
        "title": "Personalized Fashion Compatibility Modeling via\nMetapath-guided Heterogeneous Graph Learning\n",
        "abstract": "Fashion Compatibility Modeling (FCM) is a new yet challenging\ntask, which aims to automatically access the matching degree\namong a set of complementary items. Most of existing methods\nevaluate the fashion compatibility from the common perspective,\nbut overlook the user\u2019s personal preference. Inspired by this, a few\npioneers study the Personalized Fashion Compatibility Modeling\n(PFCM). Despite their significance, these PFCM methods mainly\nconcentrate on the user and item entities, as well as their interac-\ntions, but ignore the attribute entities, which contain rich semantics.\nTo address this problem, we propose to fully explore the related\nentities and their relations involved in PFCM to boost the PFCM\nperformance. This is, however, non-trivial due to the heteroge-\nneous contents of different entities, embeddings for new users, and\nvarious high-order relations. Towards these ends, we present a\nnovel metapath-guided personalized fashion compatibility mod-\neling, dubbed as MG-PFCM. In particular, we creatively build a\nheterogeneous graph to unify the three types of entities (i.e., users,\nitems, and attributes) and their relations (i.e., user-item interac-\ntions, item-item matching relations, and item-attribute association\nrelations). Thereafter, we design a multi-modal content-oriented\nuser embedding module to learn user representations by inherit-\ning the contents of their interacted items. Meanwhile, we define\nthe user-oriented and item-oriented metapaths, and perform the\nmetapath-guided heterogeneous graph learning to enhance the user\nand item embeddings. In addition, we introduce the contrastive\nregularization to improve the model performance. We conduct ex-\ntensive experiments on the real-world benchmark dataset, which\nverifies the superiority of our proposed scheme over several cutting-\nedge baselines. As a byproduct, we have released our source codes\nto benefit other researchers.\n "
    }
]